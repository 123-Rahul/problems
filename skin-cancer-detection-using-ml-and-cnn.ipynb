{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10258391,"sourceType":"datasetVersion","datasetId":6345910},{"sourceId":10376531,"sourceType":"datasetVersion","datasetId":6427593},{"sourceId":10533969,"sourceType":"datasetVersion","datasetId":6517801},{"sourceId":10611125,"sourceType":"datasetVersion","datasetId":6569151}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nfrom sklearn.metrics import (\n    confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n)\nimport matplotlib.pyplot as plt\n\n# Load the metadata from the Excel file\nmetadata_path = '/kaggle/input/isic-2019-skin-cancer/data.xlsx'\nmetadata = pd.read_excel(metadata_path)\n\n# Path to the main image folder\nimage_folder_path = '/kaggle/input/isic-2019-skin-cancer/Dataset/Dataset'\n\n# Check if all images exist in their respective folders\nmissing_images = []\nfor _, row in metadata.iterrows():\n    disease_type = row['DiseaseType']  # Folder name\n    image_name = row['ImageName']      # File name\n    image_path = os.path.join(image_folder_path, disease_type, image_name)\n    if not os.path.exists(image_path):\n        missing_images.append(image_name)\n\nif missing_images:\n    print(f\"Missing images: {missing_images}\")\nelse:\n    print(\"All images are available!\")\n\n# Add a new column with the full file paths\nmetadata['filepath'] = metadata.apply(lambda x: os.path.join(image_folder_path, x['DiseaseType'], x['ImageName']), axis=1)\n\n# Encode labels (DiseaseType) into integers\nmetadata['label_encoded'] = metadata['DiseaseType'].astype('category').cat.codes\n\n# Split data into train+validation and test sets (80% train+val, 20% test)\ntrain_val_df, test_df = train_test_split(\n    metadata, \n    test_size=0.2, \n    stratify=metadata['DiseaseType'], \n    random_state=42\n)\n\n# Further split train+val into train and validation (80% train, 20% validation)\ntrain_df, val_df = train_test_split(\n    train_val_df, \n    test_size=0.2, \n    stratify=train_val_df['DiseaseType'], \n    random_state=42\n)\n\nprint(f\"Training samples: {len(train_df)}\")\nprint(f\"Validation samples: {len(val_df)}\")\nprint(f\"Testing samples: {len(test_df)}\")\n\n# Preprocessing function for images\ndef preprocess_image(file_path, label):\n    img = tf.io.read_file(file_path)\n    img = tf.image.decode_jpeg(img, channels=3)  # Decode JPEG files\n    img = tf.image.resize(img, [224, 224])  # Resize to match ResNet50 input size\n    img = img / 255.0  # Normalize pixel values to [0, 1]\n    return img, label\n\n# Prepare TensorFlow datasets\ndef create_tf_dataset(dataframe, batch_size=32, shuffle=False):\n    file_paths = dataframe['filepath'].values\n    labels = dataframe['label_encoded'].values\n    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n    dataset = dataset.map(preprocess_image)\n    if shuffle:\n        dataset = dataset.shuffle(buffer_size=1000)\n    dataset = dataset.batch(batch_size)\n    return dataset\n\n# Create train, validation, and test datasets\nbatch_size = 32\ntrain_ds = create_tf_dataset(train_df, batch_size=batch_size, shuffle=True)\nval_ds = create_tf_dataset(val_df, batch_size=batch_size)\ntest_ds = create_tf_dataset(test_df, batch_size=batch_size)\n\n# Define the ResNet50 model\nbase_model = ResNet50(\n    weights='imagenet',  # Load weights pre-trained on ImageNet\n    include_top=False,   # Exclude the fully connected layers\n    input_shape=(224, 224, 3)  # Input shape for ResNet50\n)\n\n# Freeze the base model layers\nbase_model.trainable = False\n\n# Add custom layers on top of ResNet50\nx = base_model.output\nx = GlobalAveragePooling2D()(x)  # Add global average pooling layer\nx = Dense(1024, activation='relu')(x)  # Fully connected layer\nx = Dense(512, activation='relu')(x)   # Another fully connected layer\npredictions = Dense(len(metadata['label_encoded'].unique()), activation='softmax')(x)  # Output layer\n\n# Create the complete model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Compile the model\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0001),\n    loss='sparse_categorical_crossentropy',  # Sparse categorical crossentropy for integer labels\n    metrics=['accuracy']\n)\n\n# Train the model\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=20  # Adjust the number of epochs as needed\n)\n\n# Plot training and validation accuracy/loss\ndef plot_metrics(history, title_prefix=\"\"):\n    # Extract metrics\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs_range = range(1, len(acc) + 1)\n    \n    # Plot Accuracy\n    plt.figure(figsize=(12, 6))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, acc, label='Training Accuracy')\n    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.title(f\"{title_prefix} Accuracy\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    \n    # Plot Loss\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, loss, label='Training Loss')\n    plt.plot(epochs_range, val_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.title(f\"{title_prefix} Loss\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.tight_layout()\n    plt.show()\n\n# Plot metrics for initial training\nplot_metrics(history, title_prefix=\"Initial Training\")\n\n# Evaluate the model on the test set\ntest_loss, test_accuracy = model.evaluate(test_ds)\nprint(f\"Test Loss: {test_loss:.4f}\")\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\n\n# Fine-tune the base model\nbase_model.trainable = True  # Unfreeze the base model\nmodel.compile(\n    optimizer=Adam(learning_rate=1e-5),  # Use a lower learning rate for fine-tuning\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Continue training with fine-tuning\nfine_tune_history = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=30  # Additional epochs for fine-tuning\n)\n\n# Plot metrics for fine-tuning\nplot_metrics(fine_tune_history, title_prefix=\"Fine-Tuning\")\n\n# Evaluate after fine-tuning\nfinal_test_loss, final_test_accuracy = model.evaluate(test_ds)\nprint(f\"Final Test Loss: {final_test_loss:.4f}\")\nprint(f\"Final Test Accuracy after Fine-Tuning: {final_test_accuracy:.4f}\")\n\n# Save the model in the Kaggle working directory\nmodel.save('/kaggle/working/resnet50_model.h5')  # Save in HDF5 format\n\n# Evaluation Metrics and Confusion Matrix\ny_true = []\ny_pred = []\n\nfor images, labels in test_ds:\n    y_true.extend(labels.numpy())  # True labels\n    predictions = model.predict(images)\n    y_pred.extend(np.argmax(predictions, axis=1))  # Predicted labels\n\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\n\n# Confusion Matrix\nclass_names = metadata['DiseaseType'].astype('category').cat.categories.tolist()\ncm = confusion_matrix(y_true, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(cmap='Blues', xticks_rotation='vertical')\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n# Classification Report\nprint(\"Classification Report:\")\nprint(classification_report(y_true, y_pred, target_names=class_names))\n\n# Additional Metrics\naccuracy = accuracy_score(y_true, y_pred)\nprecision = precision_score(y_true, y_pred, average='weighted')\nrecall = recall_score(y_true, y_pred, average='weighted')\nf1 = f1_score(y_true, y_pred, average='weighted')\n\nprint(f\"Accuracy: {accuracy:.2f}\")\nprint(f\"Precision: {precision:.2f}\")\nprint(f\"Recall: {recall:.2f}\")\nprint(f\"F1-Score: {f1:.2f}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T16:23:33.688218Z","iopub.execute_input":"2025-01-29T16:23:33.688532Z","iopub.status.idle":"2025-01-29T18:19:42.432217Z","shell.execute_reply.started":"2025-01-29T16:23:33.688507Z","shell.execute_reply":"2025-01-29T18:19:42.431480Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import necessary libraries\nfrom tensorflow.keras.models import load_model  # To load the saved model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nimport numpy as np\n\n# Load the saved model\nmodel = load_model('/kaggle/working/resnet50_model.h5')  # Load the model\nprint(\"Model loaded successfully!\")\nclass_names = ['ak', 'bcc', 'bkl', 'df', 'mel','nv', 'scc', 'vasc']\n# Function to preprocess an image\ndef preprocess_image(image_path):\n    img = load_img(image_path, target_size=(224, 224))  # Resize image to model input size\n    img_array = img_to_array(img)  # Convert image to array\n    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n    img_array = img_array / 255.0  # Normalize pixel values to [0, 1]\n    return img_array\n\n# Path to the test image (update with your actual file path)\nimage_path = '/kaggle/input/input2/WhatsApp Image 2025-01-29 at 13.48.11_01021e61.jpg'  # Replace with the actual image path\n\n# Preprocess and predict\ntry:\n    test_image = preprocess_image(image_path)\n    predictions = model.predict(test_image)\n    predicted_index = np.argmax(predictions)  # Get the index of the highest prediction score\n    predicted_class = class_names[predicted_index]\n    print(f\"Predicted Class: {predicted_class}\")\nexcept Exception as e:\n    print(f\"Error in processing or prediction: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:19:42.433275Z","iopub.execute_input":"2025-01-29T18:19:42.433754Z","iopub.status.idle":"2025-01-29T18:19:46.975492Z","shell.execute_reply.started":"2025-01-29T18:19:42.433730Z","shell.execute_reply":"2025-01-29T18:19:46.974655Z"}},"outputs":[],"execution_count":null}]}